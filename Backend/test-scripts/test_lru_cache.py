"""
Test LRU Cache Migration implementation (Quick Win #4).
Verifies that L1 cache uses true LRU eviction instead of FIFO.
"""

import time


def test_lru_cache_initialization():
    """Test that cache initializes with access time tracking."""
    from core.cache import EmbeddingCache

    print("=" * 80)
    print("Testing LRU Cache Migration (Quick Win #4)")
    print("=" * 80)

    cache = EmbeddingCache()

    # Verify access time tracking dict exists
    assert hasattr(cache, '_l1_cache'), "L1 cache should exist"
    assert hasattr(cache, '_l1_cache_access_time'), "Access time tracking should exist"
    assert isinstance(cache._l1_cache, dict), "L1 cache should be a dict"
    assert isinstance(cache._l1_cache_access_time, dict), "Access time tracking should be a dict"

    print("\n‚úÖ Cache initialized with access time tracking")
    print(f"   _l1_cache: {type(cache._l1_cache)}")
    print(f"   _l1_cache_access_time: {type(cache._l1_cache_access_time)}")


def test_lru_eviction_behavior():
    """
    Test that LRU eviction removes least recently used items.

    Scenario:
    1. Fill cache to capacity (1000 items)
    2. Access item #1 to refresh its access time
    3. Add item #1001 (should evict oldest item, NOT item #1)
    4. Verify item #1 is still in cache
    """
    from core.cache import EmbeddingCache

    print("\n" + "=" * 80)
    print("Testing LRU Eviction Behavior")
    print("=" * 80)

    cache = EmbeddingCache()

    # Step 1: Fill cache to capacity (1000 items)
    print("\nStep 1: Filling cache with 1000 items...")
    for i in range(1000):
        cache.set(f"text_{i}", [float(i)] * 768)  # Simulate 768-dim embedding
        time.sleep(0.001)  # Small delay to ensure different timestamps

    print(f"‚úÖ Cache filled: {len(cache._l1_cache)} items")
    assert len(cache._l1_cache) == 1000, "Cache should have exactly 1000 items"

    # Step 2: Access item #0 to refresh its access time
    print("\nStep 2: Accessing item #0 to refresh access time...")
    time.sleep(0.01)  # Delay to make access time clearly different
    accessed_item = cache.get("text_0")
    assert accessed_item is not None, "Item #0 should be in cache"
    print(f"‚úÖ Item #0 accessed successfully")

    # Record access times before adding new item
    item_0_access_time = cache._l1_cache_access_time.get(cache._hash_text("text_0"))
    item_1_access_time = cache._l1_cache_access_time.get(cache._hash_text("text_1"))

    print(f"   Item #0 access time: {item_0_access_time}")
    print(f"   Item #1 access time: {item_1_access_time}")
    assert item_0_access_time > item_1_access_time, "Item #0 should have newer access time"

    # Step 3: Add item #1000 (should evict oldest item, which is now item #1)
    print("\nStep 3: Adding item #1000 (should trigger LRU eviction)...")
    time.sleep(0.01)
    cache.set("text_1000", [float(1000)] * 768)

    print(f"‚úÖ Item #1000 added, cache size: {len(cache._l1_cache)}")
    assert len(cache._l1_cache) == 1000, "Cache should maintain 1000 items after eviction"

    # Step 4: Verify LRU behavior (item #0 should still be in cache, item #1 should be evicted)
    print("\nStep 4: Verifying LRU behavior...")

    item_0_still_exists = cache._hash_text("text_0") in cache._l1_cache
    item_1_exists = cache._hash_text("text_1") in cache._l1_cache
    item_1000_exists = cache._hash_text("text_1000") in cache._l1_cache

    print(f"   Item #0 in cache: {item_0_still_exists}")
    print(f"   Item #1 in cache: {item_1_exists}")
    print(f"   Item #1000 in cache: {item_1000_exists}")

    assert item_0_still_exists, "Item #0 should still be in cache (was recently accessed)"
    assert not item_1_exists, "Item #1 should be evicted (least recently used)"
    assert item_1000_exists, "Item #1000 should be in cache (just added)"

    print("\n‚úÖ LRU eviction working correctly!")
    print("   ‚úì Recently accessed item #0 retained")
    print("   ‚úì Least recently used item #1 evicted")
    print("   ‚úì New item #1000 added successfully")


def test_access_time_tracking():
    """Test that access times are updated on cache hits."""
    from core.cache import EmbeddingCache

    print("\n" + "=" * 80)
    print("Testing Access Time Tracking")
    print("=" * 80)

    cache = EmbeddingCache()

    # Add an item
    cache.set("test_item", [1.0, 2.0, 3.0])
    initial_access_time = cache._l1_cache_access_time.get(cache._hash_text("test_item"))

    print(f"\nInitial access time: {initial_access_time}")

    # Wait and access again
    time.sleep(0.01)
    cache.get("test_item")
    updated_access_time = cache._l1_cache_access_time.get(cache._hash_text("test_item"))

    print(f"Updated access time: {updated_access_time}")

    assert updated_access_time > initial_access_time, "Access time should be updated on get()"
    print("‚úÖ Access time correctly updated on cache hit")


def test_fifo_vs_lru_comparison():
    """
    Compare FIFO vs LRU behavior to demonstrate improvement.

    FIFO (old behavior):
    - Evicts first item added, regardless of usage
    - Hot items can be evicted if added early

    LRU (new behavior):
    - Evicts least recently accessed item
    - Hot items stay in cache
    """
    from core.cache import EmbeddingCache

    print("\n" + "=" * 80)
    print("FIFO vs LRU Behavior Comparison")
    print("=" * 80)

    cache = EmbeddingCache()

    # Simulate a hot item that's accessed frequently
    print("\nSimulating hot item access pattern...")
    cache.set("hot_item", [1.0] * 768)
    cache.set("cold_item_1", [2.0] * 768)

    # Fill cache to near capacity
    for i in range(998):
        cache.set(f"filler_{i}", [float(i)] * 768)
        time.sleep(0.0001)

    # Access hot item multiple times
    for _ in range(5):
        cache.get("hot_item")
        time.sleep(0.001)

    print(f"Cache size before adding new item: {len(cache._l1_cache)}")

    # Add one more item (should trigger eviction)
    cache.set("new_item", [999.0] * 768)

    # Check if hot item survived
    hot_item_exists = cache._hash_text("hot_item") in cache._l1_cache
    print(f"\n‚úÖ Hot item survived eviction: {hot_item_exists}")

    assert hot_item_exists, "Hot item should survive with LRU (would be evicted with FIFO)"

    print("\n" + "=" * 80)
    print("LRU Improvement Verified!")
    print("=" * 80)
    print("\nWith FIFO (old):")
    print("  ‚ùå Hot items evicted if added early")
    print("  ‚ùå Cache inefficient for repeated access patterns")
    print("\nWith LRU (new):")
    print("  ‚úÖ Hot items stay in cache")
    print("  ‚úÖ 10-15% higher hit rate expected")


if __name__ == "__main__":
    test_lru_cache_initialization()
    test_access_time_tracking()
    test_lru_eviction_behavior()
    test_fifo_vs_lru_comparison()

    print("\n" + "=" * 80)
    print("üéâ Quick Win #4: LRU Cache Migration - FULLY FUNCTIONAL!")
    print("=" * 80)
    print("\nExpected Impact:")
    print("  ‚Ä¢ Cache hit rate: 75-80% ‚Üí 85-90% (+10%)")
    print("  ‚Ä¢ Embedding generation: 1-2s ‚Üí 0.5-1s for cache hits")
    print("  ‚Ä¢ Scoring phase: 2-3s ‚Üí 1-1.5s")
    print("  ‚Ä¢ Hot items stay in cache (frequently accessed data)")
    print("=" * 80)
